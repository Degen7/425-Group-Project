{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "425 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pyranges as pr\n",
    "import sqlite3\n",
    "\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import os \n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chromosome_1_ = 'Final_bed_files\\Chromosomes\\Arabidopsis_thaliana.TAIR10.dna.chromosome.1.fa'\n",
    "Chromosome_2_ = 'Final_bed_files\\Chromosomes\\Arabidopsis_thaliana.TAIR10.dna.chromosome.2.fa'\n",
    "Chromosome_3_ = 'Final_bed_files\\Chromosomes\\Arabidopsis_thaliana.TAIR10.dna.chromosome.3.fa'\n",
    "Chromosome_4_ = 'Final_bed_files\\Chromosomes\\Arabidopsis_thaliana.TAIR10.dna.chromosome.4.fa'\n",
    "Chromosome_5_ = 'Final_bed_files\\Chromosomes\\Arabidopsis_thaliana.TAIR10.dna.chromosome.5.fa'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: CCCTAAACCCTAAACCCTAAACCCTAAACCTCTGAATCCTTAATCCCTAA ...\n",
      "Sequence: NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN ...\n",
      "Sequence: NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN ...\n",
      "Sequence: NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN ...\n",
      "Sequence: TATACCATGTACCCTCAACCTTAAAACCCTAAAACCTATACTATAAATCT ...\n"
     ]
    }
   ],
   "source": [
    "# Putting all the chromosomes in a list with a size of 5\n",
    "seqs_List= []\n",
    "\n",
    "file_paths = [Chromosome_1_,Chromosome_2_,Chromosome_3_,Chromosome_4_,Chromosome_5_]\n",
    "\n",
    "# Iterate over each file\n",
    "for file_path in file_paths:\n",
    "   with open(file_path, \"r\") as handle:\n",
    "\n",
    "    # Open the file\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            sequence_id = record.id\n",
    "            #print(\"Sequence ID:\", sequence_id)\n",
    "            description = record.description\n",
    "            #print(\"Description:\", description)\n",
    "            sequence = record.seq\n",
    "            seqs_List.append(str(sequence))\n",
    "            print(\"Sequence:\", str(sequence[:50]), \"...\")  # Print first 50 characters of the sequence\n",
    "            #print(\"Sequence length:\", len(sequence))  # Print length of the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(filename):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(filename, sep='\\t', header=None)\n",
    "\n",
    "    # Set column names\n",
    "    df.columns = ['chromosome', 'start', 'end', 'name', 'score', 'strand', 'stuff', 'things', 'who', 'ahh', 'scream', 'ska', 'die', 'grr']\n",
    "\n",
    "    # Calculate new positions based on existing start and end positions\n",
    "    df['dif'] = df['end'] - df['start']\n",
    "    df['mid'] = df['dif'] // 2\n",
    "    df['midpoint'] = df['start'] + df['mid']\n",
    "    df['new_start'] = df['midpoint'] - 400\n",
    "    df['new_end'] = df['midpoint'] + 400\n",
    "    df['dif_new'] = df['new_end'] - df['new_start']\n",
    "\n",
    "    # Create a new DataFrame with selected columns\n",
    "    df_new = pd.DataFrame({\n",
    "        'chromosome': df['chromosome'],\n",
    "        'start': df['start'],\n",
    "        'end': df['end'],\n",
    "        'midpoint': df['midpoint'],\n",
    "        'dif': df['dif'],\n",
    "        'new_start': df['new_start'], #new start and end are from the midpoint out 250 each way\n",
    "        'new_end': df['new_end'],\n",
    "        'position_difference_new': df['dif_new']\n",
    "    })\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFile = \"Final_bed_files/SRP034156_BedFiles/SRX391990.target.all.bed\"\n",
    "directory = \"Final_bed_files//test_bedFiles\"\n",
    "\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".bed\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = process_dataframe(file_path)\n",
    "        dataframes.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_seqs(df, data_list):\n",
    "    dfs = []\n",
    "    for index, row in df.iterrows():\n",
    "        #Changing the chromosome to an int that can be used to find the correct index of the string of chromosomes\n",
    "        chromosome_label = row['chromosome']\n",
    "        chromosome_number = int(chromosome_label.replace('Chr', ''))\n",
    "        data = data_list[chromosome_number - 1]\n",
    "        extracted_data = data[row['new_start']:row['new_end']] #gets the peak sequence\n",
    "        size = len(extracted_data)\n",
    "        if(size < 500):\n",
    "            Add_num_N = 500 - size\n",
    "            #print(size)\n",
    "            print(\"N to add: \", Add_num_N)\n",
    "            extracted_data += 'N' * Add_num_N\n",
    "            new_size = len(extracted_data)\n",
    "            #print(new_size)\n",
    "            size = new_size\n",
    "\n",
    "        df_extracted = pd.DataFrame({ #saves it as a new dataframe\n",
    "            'chromosome': [chromosome_label],\n",
    "            'start': [row['new_start']],\n",
    "            'end': [row['new_end']],\n",
    "            'size': [size],\n",
    "            'data': [extracted_data]\n",
    "        })\n",
    "\n",
    "        dfs.append(df_extracted)\n",
    "\n",
    "    result_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(\"done\")\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1: 24019 rows x 8 columns\n",
      "DataFrame 2: 20457 rows x 8 columns\n",
      "DataFrame 3: 19464 rows x 8 columns\n",
      "DataFrame 4: 22100 rows x 8 columns\n",
      "DataFrame 5: 16752 rows x 8 columns\n",
      "DataFrame 6: 22932 rows x 8 columns\n",
      "DataFrame 7: 29238 rows x 8 columns\n",
      "DataFrame 8: 13905 rows x 8 columns\n",
      "DataFrame 9: 13879 rows x 8 columns\n",
      "DataFrame 10: 11987 rows x 8 columns\n"
     ]
    }
   ],
   "source": [
    "#Check size of each dataframe within the list\n",
    "for i, df in enumerate(dataframes):\n",
    "    num_rows, num_columns = df.shape\n",
    "    print(f\"DataFrame {i+1}: {num_rows} rows x {num_columns} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1 - No rows found with position_difference_new not equal to 600.\n",
      "DataFrame 2 - No rows found with position_difference_new not equal to 600.\n",
      "DataFrame 3 - No rows found with position_difference_new not equal to 600.\n",
      "DataFrame 4 - No rows found with position_difference_new not equal to 600.\n",
      "DataFrame 5 - No rows found with position_difference_new not equal to 600.\n",
      "DataFrame 6 - No rows found with position_difference_new not equal to 600.\n",
      "DataFrame 7 - No rows found with position_difference_new not equal to 600.\n",
      "DataFrame 8 - No rows found with position_difference_new not equal to 600.\n",
      "DataFrame 9 - No rows found with position_difference_new not equal to 600.\n",
      "DataFrame 10 - No rows found with position_difference_new not equal to 600.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each DataFrame in the list\n",
    "for i, df in enumerate(dataframes):\n",
    "    # Filter rows where position_difference_new is not equal to 600\n",
    "    filtered_df = df[df['position_difference_new'] != 800]\n",
    "    \n",
    "    # Print the values of position_difference_new for filtered rows\n",
    "    if not filtered_df.empty:\n",
    "        print(f\"DataFrame {i+1} - Values of position_difference_new not equal to 600:\")\n",
    "        print(filtered_df['position_difference_new'])\n",
    "    else:\n",
    "        print(f\"DataFrame {i+1} - No rows found with position_difference_new not equal to 600.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
