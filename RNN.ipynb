{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third model used is a Recurrent Neural Network (RNN) using Pytorch. An RNN was chosen as it has a couple advantages when searching through a sequence for binding sites or other information that a sequence can tell us. One of the design features allow RNN's to handle temporal dependancies, the effects of previous inputs on the current decision making, which is vital when looking at sequences as the surrounding base pairs change the information that is given from the one being observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['chromosome', 'start', 'end', 'size', 'peak_seq', 'label',\n",
      "       'one_hot_data'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pkl_file = \"test_1_df.pkl\"\n",
    "test_df = load_data(pkl_file)\n",
    "X = test_df['one_hot_data']\n",
    "y = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11987"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11987"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6956\n",
      "Epoch [2/10], Loss: 0.6917\n",
      "Epoch [3/10], Loss: 0.6887\n",
      "Epoch [4/10], Loss: 0.6861\n",
      "Epoch [5/10], Loss: 0.6840\n",
      "Epoch [6/10], Loss: 0.6826\n",
      "Epoch [7/10], Loss: 0.6817\n",
      "Epoch [8/10], Loss: 0.6813\n",
      "Epoch [9/10], Loss: 0.6810\n",
      "Epoch [10/10], Loss: 0.6808\n",
      "AUC: 0.5087\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, input_data, labels, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "def calculate_auc(model, input_data, labels):\n",
    "    with torch.no_grad():\n",
    "        predictions = torch.sigmoid(model(input_data)).numpy()\n",
    "        auc = roc_auc_score(labels.numpy(), predictions)\n",
    "        print(f'AUC: {auc:.4f}')\n",
    "        return auc\n",
    "\n",
    "# Example usage:\n",
    "input_size = 100\n",
    "hidden_size = 64\n",
    "num_layers = 50\n",
    "output_size = 37\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy input data and labels (replace with your actual data)\n",
    "input_data = torch.randn(32, 5, input_size)  # Batch size 32, sequence length 5\n",
    "labels = torch.randint(0, 2, (32, output_size)).float()\n",
    "\n",
    "# Train the model\n",
    "train_model(model, criterion, optimizer, input_data, labels)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = calculate_auc(model, input_data, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
